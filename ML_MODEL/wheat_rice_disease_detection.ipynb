{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Detection System\n",
    "## Multi-Crop Disease Classification using Deep Learning\n",
    "\n",
    "**Dataset**: Comprehensive plant disease dataset  \n",
    "**Model**: MobileNetV2 with transfer learning  \n",
    "**Output**: Trained model (.h5), TFLite model, evaluation metrics\n",
    "\n",
    "## Setup Instructions\n",
    "1. Install Python 3.8-3.10\n",
    "2. Install dependencies: `pip install -r requirements.txt`\n",
    "3. Ensure dataset is in `final_dataset/` folder with train/val/test subfolders\n",
    "4. Run cells sequentially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== PLANT DISEASE DETECTION SETUP ===\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "\n",
    "print(\"\\nChecking dependencies...\")\n",
    "dependencies = [\n",
    "    'tensorflow>=2.8.0,<2.14.0',\n",
    "    'matplotlib>=3.5.0',\n",
    "    'scikit-learn>=1.0.0',\n",
    "    'opencv-python>=4.5.0',\n",
    "    'seaborn>=0.11.0',\n",
    "    'numpy>=1.21.0,<2.0.0',\n",
    "    'pandas>=1.3.0',\n",
    "    'pillow>=8.0.0'\n",
    "]\n",
    "\n",
    "missing_deps = []\n",
    "for dep in dependencies:\n",
    "    package_name = dep.split('>=')[0].split('==')[0]\n",
    "    try:\n",
    "        __import__(package_name.replace('-', '_'))\n",
    "        print(f\"✓ {package_name} available\")\n",
    "    except ImportError:\n",
    "        missing_deps.append(dep)\n",
    "        print(f\"✗ {package_name} missing\")\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"\\nInstalling missing dependencies...\")\n",
    "    for dep in missing_deps:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', dep], check=True, capture_output=True)\n",
    "            print(f\"✓ {dep.split('>=')[0]} installed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ {dep.split('>=')[0]} installation failed\")\n",
    "            print(f\"  Error: {e.stderr.decode() if e.stderr else 'Unknown error'}\")\n",
    "\n",
    "print(\"\\n✓ Dependencies check complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"=== TENSORFLOW CONFIGURATION ===\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"Available GPUs: {len(gpus)}\")\n",
    "\n",
    "use_gpu = False\n",
    "if gpus:\n",
    "    print(\"GPU(s) detected!\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu}\")\n",
    "    \n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✓ GPU memory growth enabled\")\n",
    "        \n",
    "        with tf.device('/GPU:0'):\n",
    "            test_tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "            print(f\"✓ Test tensor created on GPU: {test_tensor.device}\")\n",
    "        \n",
    "        try:\n",
    "            policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "            tf.keras.mixed_precision.set_global_policy(policy)\n",
    "            print(\"✓ Mixed precision training enabled\")\n",
    "        except Exception as e:\n",
    "            print(f\"Mixed precision setup failed: {e}\")\n",
    "        \n",
    "        use_gpu = True\n",
    "        print(\"✓ GPU training ready!\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration failed: {e}\")\n",
    "        print(\"Falling back to CPU training\")\n",
    "        use_gpu = False\n",
    "else:\n",
    "    print(\"No GPU detected - using CPU training\")\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"✓ Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "data_path = 'final_dataset'\n",
    "\n",
    "print(\"=== DATASET EXPLORATION ===\")\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"❌ Dataset folder '{data_path}' not found!\")\n",
    "    print(\"Please ensure the dataset is in the correct location with train/val/test subfolders\")\n",
    "    raise FileNotFoundError(f\"Dataset folder '{data_path}' not found\")\n",
    "\n",
    "total_classes = set()\n",
    "total_images = 0\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(data_path, split)\n",
    "    if os.path.exists(split_path):\n",
    "        classes = [d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))]\n",
    "        split_images = 0\n",
    "        for class_name in classes:\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            image_files = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG', '*.png', '*.PNG']:\n",
    "                image_files.extend(glob.glob(os.path.join(class_path, ext)))\n",
    "            split_images += len(image_files)\n",
    "            total_classes.add(class_name)\n",
    "        print(f\"✓ {split.upper()}: {len(classes)} classes, {split_images} images\")\n",
    "        total_images += split_images\n",
    "    else:\n",
    "        print(f\"⚠️  {split.upper()} folder not found in dataset\")\n",
    "\n",
    "print(f\"\\n✓ Total dataset: {len(total_classes)} unique classes, {total_images} images\")\n",
    "print(\"✓ Dataset ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    os.path.join(data_path, 'train'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    os.path.join(data_path, 'val'),\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "steps_per_epoch = train_gen.samples // batch_size\n",
    "validation_steps = val_gen.samples // batch_size\n",
    "\n",
    "print(\"Data generators created\")\n",
    "print(f\"Classes: {train_gen.num_classes}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    with tf.device('/GPU:0'):\n",
    "        base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "        base.trainable = False\n",
    "        \n",
    "        x = GlobalAveragePooling2D()(base.output)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "        if tf.keras.mixed_precision.global_policy().name == 'mixed_float16':\n",
    "            x = tf.keras.layers.Activation('linear', dtype='float32')(x)\n",
    "        \n",
    "        out = Dense(train_gen.num_classes, activation='softmax', dtype='float32')(x)\n",
    "        model = Model(base.input, out)\n",
    "        \n",
    "        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(Adam(learning_rate=1e-4))\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    base.trainable = False\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    out = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "    model = Model(base.input, out)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(f\"Model built: {model.count_params():,} parameters\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7),\n",
    "    ModelCheckpoint('models/best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"Starting GPU training...\")\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=20,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "else:\n",
    "    print(\"Starting CPU training...\")\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=20,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "model.save('models/final_model.h5')\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final accuracy: {max(history.history['val_accuracy']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen.reset()\n",
    "preds = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(\"=== CLASSIFICATION REPORT ===\")\n",
    "class_names = list(val_gen.class_indices.keys())\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('models/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved: {len(tflite_model) / 1024:.2f} KB\")\n",
    "print(\"Ready for mobile deployment!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CREATING IoT MODEL ===\")\n",
    "\n",
    "try:\n",
    "    with open('class_indices.json', 'r') as f:\n",
    "        all_classes = json.load(f)\n",
    "    print(f\"✓ Loaded {len(all_classes)} classes from class_indices.json\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️  class_indices.json not found, using default classes\")\n",
    "    all_classes = {}\n",
    "\n",
    "important_classes = [\n",
    "    \"paddy_normal\",\n",
    "    \"paddy_blast\", \n",
    "    \"paddy_brown_spot\",\n",
    "    \"wheat_Healthy\",\n",
    "    \"wheat_septoria\",\n",
    "    \"Tomato_healthy\"\n",
    "]\n",
    "\n",
    "print(f\"Reduced classes from {len(all_classes)} to {len(important_classes)}\")\n",
    "\n",
    "def create_ultra_small_model():\n",
    "    print(\"Creating ultra-small CNN model...\")\n",
    "    \n",
    "    img_size = 64\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(img_size, img_size, 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(8, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(len(important_classes), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, img_size\n",
    "\n",
    "iot_model, img_size = create_ultra_small_model()\n",
    "\n",
    "print(f\"Model parameters: {iot_model.count_params():,}\")\n",
    "print(f\"Input size: {img_size}x{img_size}\")\n",
    "print(f\"Classes: {len(important_classes)}\")\n",
    "\n",
    "iot_model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
